{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45f7993a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Deployment\n",
    "\n",
    "Let's deploy 8 bit quantized Foundation AI Foundation-Sec-8B-Instruct model onto Amazon SageMaker AI. <br>\n",
    "You can use the model deployed by this notebook for inference.  Refer to [the inference notebook](./inference.ipynb) for sample code.\n",
    "\n",
    "As a prerequisite, please launch JupyterLab on SageMaker in your AWS environment. For more details, visit: \n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-jl.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49ce7d",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c9c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages:\n",
    "!pip install sagemaker boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ee8e87",
   "metadata": {},
   "source": [
    "### Configuration and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318779b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "\n",
    "AWS_REGION = \"us-west-2\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = AWS_REGION \n",
    "ACCOUNT_ID = \"\"  # Add your AWS account ID here\n",
    "\n",
    "MODEL_NAME = \"fdtn-ai/Foundation-Sec-8B-Instruct-Q8_0-GGUF\"\n",
    "INSTANCE_TYPE = \"ml.c6i.4xlarge\"    # CPU based instance\n",
    "TIMEOUT = 900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93367654",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d550dcf9",
   "metadata": {},
   "source": [
    "We need to build a custom docker image for running the GGUF quantized model on SageMaker. The Dockerfile and the steps to build and push the image are available in the [llama_cpp_cpu](../../containers/llama_cpp_cpu) directory.\n",
    "\n",
    "Once you've published the image, specify it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "container_uri = f\"{ACCOUNT_ID}.dkr.ecr.{AWS_REGION}.amazonaws.com/fdtn-llama-cpp-cpu:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0876523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = \"Foundation-Sec-8B-Instruct-Quantized-CPU\"\n",
    "print(\"Deploying to endpoint: \", endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbde6dd8",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3180dfb",
   "metadata": {},
   "source": [
    "You can update the `env_vars` dictionary to update env variables as needed. If you are using the image built from [llama_cpp_cpu](../../containers/llama_cpp_cpu) directory, the available environment variables can be found in [Dockerfile](../../containers/llama_cpp_cpu/Dockerfile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3f1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update other env variables as needed\n",
    "env_vars = {\n",
    "    \"HF_MODEL_ID\": MODEL_NAME,\n",
    "    \"THREADS\": 16,\n",
    "    \"CTX\": 8192,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dfedab",
   "metadata": {},
   "source": [
    "Create the SageMaker model and deploy it to an endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca80f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sagemaker.Model(\n",
    "    name=endpoint_name,\n",
    "    image_uri=container_uri,\n",
    "    role=role,\n",
    "    env=env_vars,\n",
    ")\n",
    "\n",
    "model.deploy(\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    initial_instance_count=1,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d370fe3",
   "metadata": {},
   "source": [
    "You can now refer to the [inference](./inference.ipynb) notebook to perform inference using the created endpoint."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
